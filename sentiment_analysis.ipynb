{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Importing the libraries required for this project.**\n"
      ],
      "metadata": {
        "id": "WTk5NwzmnOLn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 445,
      "metadata": {
        "id": "4syoG9CNmz_N"
      },
      "outputs": [],
      "source": [
        "# The Pandas library will be used for preprocessing and organizing text data into a data frame for further analysis.\n",
        "\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Numpy will be used for performing numerical computations on textual data converted into numerical vectors.\n",
        "\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "ekoYogYfnUxi"
      },
      "execution_count": 446,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The string library will be used for string manipulation.\n",
        "\n",
        "import string"
      ],
      "metadata": {
        "id": "CKUTv1oxnXSs"
      },
      "execution_count": 447,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The re (regular expression) library will be used for pattern matching in strings.\n",
        "\n",
        "import re"
      ],
      "metadata": {
        "id": "pmSAieuKnZlf"
      },
      "execution_count": 448,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NLTK provides tools and algorithms for preprocessing, feature extraction, and sentiment classification of text data.\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "ksU0CUITDJL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The TextBlob library will be used with the re library to preprocess text data and classify the sentiment of the text.\n",
        "\n",
        "from textblob import TextBlob"
      ],
      "metadata": {
        "id": "RzmrFjMhnfd_"
      },
      "execution_count": 450,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The collections library provides tools to count and store occurrences of words and phrases.\n",
        "\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "WUwBqPp5nhjz"
      },
      "execution_count": 451,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wordcloud will be used to create word clouds from text data.\n",
        "\n",
        "from wordcloud import WordCloud"
      ],
      "metadata": {
        "id": "VJocdlmknjON"
      },
      "execution_count": 452,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Matplotlib will be used for data visualisation. \n",
        "\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "o4m2lEmNnk6y"
      },
      "execution_count": 453,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Seaborn will be used for data visualisation. \n",
        "\n",
        "import seaborn as sns\n"
      ],
      "metadata": {
        "id": "yoFP9hcsnrE5"
      },
      "execution_count": 454,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "yo47-vkonuw9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Reading in the data**"
      ],
      "metadata": {
        "id": "pU-y752Cnxsj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab/4 Chat GPT Sentiment/dataset/chatgpt_tweets.csv\")"
      ],
      "metadata": {
        "id": "n5Ddq_rsnv6m"
      },
      "execution_count": 455,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "89C31LcwoASw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exploring the data**"
      ],
      "metadata": {
        "id": "3c22XBKvoBNL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Viewing the first five rows of the dataset for a brief overview of the structure and composition of the DataFrame. \n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "sLs6ZgDkoBwQ",
        "outputId": "7ed5bc4f-f33a-43bf-ab65-ddfe89890079"
      },
      "execution_count": 456,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              tweet_id                 created_at  like_count  quote_count  \\\n",
              "0  1598014056790622225  2022-11-30 18:00:15+00:00           2            0   \n",
              "1  1598014522098208769  2022-11-30 18:02:06+00:00       12179          889   \n",
              "2  1598014741527527435  2022-11-30 18:02:58+00:00           2            0   \n",
              "3  1598015493666766849  2022-11-30 18:05:58+00:00         561            8   \n",
              "4  1598015509420994561  2022-11-30 18:06:01+00:00           1            0   \n",
              "\n",
              "   reply_count  retweet_count  \\\n",
              "0            0              0   \n",
              "1         1130           3252   \n",
              "2            0              1   \n",
              "3           25             66   \n",
              "4            0              0   \n",
              "\n",
              "                                               tweet country  \\\n",
              "0  ChatGPT: Optimizing Language Models for Dialog...     NaN   \n",
              "1  Try talking with ChatGPT, our new AI system wh...     NaN   \n",
              "2  ChatGPT: Optimizing Language Models for Dialog...     NaN   \n",
              "3  THRILLED to share that ChatGPT, our new model ...     NaN   \n",
              "4  As of 2 minutes ago, @OpenAI released their ne...     NaN   \n",
              "\n",
              "                                         photo_url city country_code  \n",
              "0                                              NaN  NaN          NaN  \n",
              "1                                              NaN  NaN          NaN  \n",
              "2  https://pbs.twimg.com/media/Fi1J8HbWAAMv_yi.jpg  NaN          NaN  \n",
              "3  https://pbs.twimg.com/media/Fi1Km3WUYAAfzHS.jpg  NaN          NaN  \n",
              "4                                              NaN  NaN          NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8ff6c38f-d3dc-48d0-993f-98e0db14d59d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>created_at</th>\n",
              "      <th>like_count</th>\n",
              "      <th>quote_count</th>\n",
              "      <th>reply_count</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>tweet</th>\n",
              "      <th>country</th>\n",
              "      <th>photo_url</th>\n",
              "      <th>city</th>\n",
              "      <th>country_code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1598014056790622225</td>\n",
              "      <td>2022-11-30 18:00:15+00:00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>ChatGPT: Optimizing Language Models for Dialog...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1598014522098208769</td>\n",
              "      <td>2022-11-30 18:02:06+00:00</td>\n",
              "      <td>12179</td>\n",
              "      <td>889</td>\n",
              "      <td>1130</td>\n",
              "      <td>3252</td>\n",
              "      <td>Try talking with ChatGPT, our new AI system wh...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1598014741527527435</td>\n",
              "      <td>2022-11-30 18:02:58+00:00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>ChatGPT: Optimizing Language Models for Dialog...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://pbs.twimg.com/media/Fi1J8HbWAAMv_yi.jpg</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1598015493666766849</td>\n",
              "      <td>2022-11-30 18:05:58+00:00</td>\n",
              "      <td>561</td>\n",
              "      <td>8</td>\n",
              "      <td>25</td>\n",
              "      <td>66</td>\n",
              "      <td>THRILLED to share that ChatGPT, our new model ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://pbs.twimg.com/media/Fi1Km3WUYAAfzHS.jpg</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1598015509420994561</td>\n",
              "      <td>2022-11-30 18:06:01+00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>As of 2 minutes ago, @OpenAI released their ne...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ff6c38f-d3dc-48d0-993f-98e0db14d59d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8ff6c38f-d3dc-48d0-993f-98e0db14d59d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8ff6c38f-d3dc-48d0-993f-98e0db14d59d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 456
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>"
      ],
      "metadata": {
        "id": "hKYiHO9rdjoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identifying the types of data in each column. \n",
        "\n",
        "df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6769O41oITc",
        "outputId": "9abd5e3a-0598-4d0e-ac57-ce3d7168f20c"
      },
      "execution_count": 457,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tweet_id          int64\n",
              "created_at       object\n",
              "like_count        int64\n",
              "quote_count       int64\n",
              "reply_count       int64\n",
              "retweet_count     int64\n",
              "tweet            object\n",
              "country          object\n",
              "photo_url        object\n",
              "city             object\n",
              "country_code     object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 457
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>"
      ],
      "metadata": {
        "id": "LmC4RHpydpLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A summary of the dataframe, including the number of non-null values and the data type of each column.\n",
        "\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ncy8YipWoLwU",
        "outputId": "a2f2216d-0731-4324-d39d-0a166c5e62db"
      },
      "execution_count": 458,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 219294 entries, 0 to 219293\n",
            "Data columns (total 11 columns):\n",
            " #   Column         Non-Null Count   Dtype \n",
            "---  ------         --------------   ----- \n",
            " 0   tweet_id       219294 non-null  int64 \n",
            " 1   created_at     219294 non-null  object\n",
            " 2   like_count     219294 non-null  int64 \n",
            " 3   quote_count    219294 non-null  int64 \n",
            " 4   reply_count    219294 non-null  int64 \n",
            " 5   retweet_count  219294 non-null  int64 \n",
            " 6   tweet          219294 non-null  object\n",
            " 7   country        3648 non-null    object\n",
            " 8   photo_url      68446 non-null   object\n",
            " 9   city           3648 non-null    object\n",
            " 10  country_code   3645 non-null    object\n",
            "dtypes: int64(5), object(6)\n",
            "memory usage: 18.4+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>"
      ],
      "metadata": {
        "id": "6SalWK4rdq-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating the percentage of missing values in each column, and printing the column name and percentage of missing values in that column.\n",
        "\n",
        "for col in df.columns:\n",
        "  pct_missing = np.mean(df[col].isnull())\n",
        "  print('{} - {}%'.format(col, pct_missing))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIzoRlajoPo7",
        "outputId": "be1bcc2b-2c6b-4d4c-a80c-d930f37d6cb6"
      },
      "execution_count": 459,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tweet_id - 0.0%\n",
            "created_at - 0.0%\n",
            "like_count - 0.0%\n",
            "quote_count - 0.0%\n",
            "reply_count - 0.0%\n",
            "retweet_count - 0.0%\n",
            "tweet - 0.0%\n",
            "country - 0.9833647979424882%\n",
            "photo_url - 0.6878801973606209%\n",
            "city - 0.9833647979424882%\n",
            "country_code - 0.9833784782073381%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>\n",
        "\n"
      ],
      "metadata": {
        "id": "S3wOemPedsfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Returns the sum of missing values in each column of the dataframe.\n",
        "\n",
        "df.isnull().sum()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXUsPUKDoSiL",
        "outputId": "d27b5c77-05f5-4ae2-9d5b-1ab38e590cb1"
      },
      "execution_count": 460,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tweet_id              0\n",
              "created_at            0\n",
              "like_count            0\n",
              "quote_count           0\n",
              "reply_count           0\n",
              "retweet_count         0\n",
              "tweet                 0\n",
              "country          215646\n",
              "photo_url        150848\n",
              "city             215646\n",
              "country_code     215649\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 460
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "YIpilOBZDVcD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Data manipulation**"
      ],
      "metadata": {
        "id": "8udHDI7zo43T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Making a copy of the dataframe for further exploration and data manipulation. \n",
        "\n",
        "df_new=df.copy()"
      ],
      "metadata": {
        "id": "i4TwV63ho_c3"
      },
      "execution_count": 461,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>\n",
        "\n"
      ],
      "metadata": {
        "id": "XpjeVLPrdua-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping the columns 'country', 'photo_url', 'city', and 'country_code' from the dataframe using the drop() method.\n",
        "\n",
        "df_new = df.drop(['country', 'photo_url', 'city', 'country_code'], axis=1)\n"
      ],
      "metadata": {
        "id": "56qonnquomGI"
      },
      "execution_count": 462,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>"
      ],
      "metadata": {
        "id": "0JBo9Tywdvag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_new.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "nla1JaNSoyVM",
        "outputId": "3036fee7-d97f-495f-8693-275cca8a48c6"
      },
      "execution_count": 463,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              tweet_id                 created_at  like_count  quote_count  \\\n",
              "0  1598014056790622225  2022-11-30 18:00:15+00:00           2            0   \n",
              "1  1598014522098208769  2022-11-30 18:02:06+00:00       12179          889   \n",
              "2  1598014741527527435  2022-11-30 18:02:58+00:00           2            0   \n",
              "3  1598015493666766849  2022-11-30 18:05:58+00:00         561            8   \n",
              "4  1598015509420994561  2022-11-30 18:06:01+00:00           1            0   \n",
              "\n",
              "   reply_count  retweet_count  \\\n",
              "0            0              0   \n",
              "1         1130           3252   \n",
              "2            0              1   \n",
              "3           25             66   \n",
              "4            0              0   \n",
              "\n",
              "                                               tweet  \n",
              "0  ChatGPT: Optimizing Language Models for Dialog...  \n",
              "1  Try talking with ChatGPT, our new AI system wh...  \n",
              "2  ChatGPT: Optimizing Language Models for Dialog...  \n",
              "3  THRILLED to share that ChatGPT, our new model ...  \n",
              "4  As of 2 minutes ago, @OpenAI released their ne...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cb4a2176-c215-40ad-ae29-1422b1cf580c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>created_at</th>\n",
              "      <th>like_count</th>\n",
              "      <th>quote_count</th>\n",
              "      <th>reply_count</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1598014056790622225</td>\n",
              "      <td>2022-11-30 18:00:15+00:00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>ChatGPT: Optimizing Language Models for Dialog...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1598014522098208769</td>\n",
              "      <td>2022-11-30 18:02:06+00:00</td>\n",
              "      <td>12179</td>\n",
              "      <td>889</td>\n",
              "      <td>1130</td>\n",
              "      <td>3252</td>\n",
              "      <td>Try talking with ChatGPT, our new AI system wh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1598014741527527435</td>\n",
              "      <td>2022-11-30 18:02:58+00:00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>ChatGPT: Optimizing Language Models for Dialog...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1598015493666766849</td>\n",
              "      <td>2022-11-30 18:05:58+00:00</td>\n",
              "      <td>561</td>\n",
              "      <td>8</td>\n",
              "      <td>25</td>\n",
              "      <td>66</td>\n",
              "      <td>THRILLED to share that ChatGPT, our new model ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1598015509420994561</td>\n",
              "      <td>2022-11-30 18:06:01+00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>As of 2 minutes ago, @OpenAI released their ne...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cb4a2176-c215-40ad-ae29-1422b1cf580c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cb4a2176-c215-40ad-ae29-1422b1cf580c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cb4a2176-c215-40ad-ae29-1422b1cf580c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 463
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>\n",
        "\n"
      ],
      "metadata": {
        "id": "4m5jri8OdxPs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating the number of words in each tweet and adding a new column for 'word count' to the dataframe.\n",
        "\n",
        "def number_of_words(df_new):\n",
        "    df_new['word_count'] = df_new['tweet'].apply(lambda x : len(str(x).split(\" \")))"
      ],
      "metadata": {
        "id": "LT5wMs9OpXa7"
      },
      "execution_count": 464,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>\n",
        "\n"
      ],
      "metadata": {
        "id": "_ZPHvXnLdyc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating the total number of characters in each tweet (excluding spaces, punctuation marks, and other special characters).\n",
        "\n",
        "def char_count(text):\n",
        "    charc = 0\n",
        "    for char in text:\n",
        "        if char != \" \":\n",
        "            charc += 1\n",
        "    return charc"
      ],
      "metadata": {
        "id": "HCY8za8CpfjR"
      },
      "execution_count": 465,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>\n",
        "\n"
      ],
      "metadata": {
        "id": "ZYLBhSOKdzfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding a new column 'stopwords_count' to the data frame that counts the number of stop words in each row of the 'tweet' column.\n",
        "\n",
        "stop_words = stopwords.words('english')\n",
        "def num_of_stopwords(df_new):\n",
        "    df_new['stopwords_count'] = df_new['tweet'].apply(lambda x: len([x for x in x.split() if x in stop_words]))"
      ],
      "metadata": {
        "id": "zlxe6GgOplcf"
      },
      "execution_count": 466,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>\n",
        "\n"
      ],
      "metadata": {
        "id": "sM7IZt3Ed01l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding a new column 'hashtag_count' to the data frame that counts the number of hashtags in each row of the 'tweet' column.\n",
        "\n",
        "def num_of_hashtags(df_new):\n",
        "    df_new['hashtag_count'] = df_new['tweet'].apply(lambda x: len([x for x in x.split() if x.startswith('#')]))\n",
        "  "
      ],
      "metadata": {
        "id": "01pAo4r5ptrJ"
      },
      "execution_count": 467,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>\n",
        "\n"
      ],
      "metadata": {
        "id": "RvbB7k1Nd18c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a function 'feat_extract' that adds four new columns to the data frame using the functions 'num_of_hashtags', 'number_of_words', 'char_count', and 'num_of_stopwords'.\n",
        "\n",
        "def feat_extract(df_new):\n",
        "    num_of_hashtags(df_new)\n",
        "    number_of_words(df_new)\n",
        "    df_new['char_count']=df_new['tweet'].apply(char_count)\n",
        "    num_of_stopwords(df_new)"
      ],
      "metadata": {
        "id": "Z8_Bs3grp5Yr"
      },
      "execution_count": 468,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "57nl9WRiqEWb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Text preprocessing**"
      ],
      "metadata": {
        "id": "aAigvHc1qFYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a function called 'remove_emoji' that takes a string as input and uses a regular expression to remove any Unicode characters that match specific ranges. \n",
        "\n",
        "def remove_emoji(string):\n",
        "        emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # Emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # Symbols & Pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # Transport & Map Symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # Regional Indicator Symbols\n",
        "                           u\"\\U00002702-\\U000027B0\"  # Miscellaneous Symbols and Arrows\n",
        "                           u\"\\U000024C2-\\U0001F251\"  # Enclosed Characters\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "        return emoji_pattern.sub(r'', string) "
      ],
      "metadata": {
        "id": "8zJ4vBY7qGCi"
      },
      "execution_count": 469,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>\n",
        "\n"
      ],
      "metadata": {
        "id": "7OIWdQiod3kI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a function called 'remove_apostrophe' function which uses a regular expression to remove apostrophes from a string. \n",
        "\n",
        "def remove_apostrophe(string):\n",
        "    apostrophe_pattern = re.compile(r\"[’‘]\")  # Matches apostrophes\n",
        "    return apostrophe_pattern.sub('', string)"
      ],
      "metadata": {
        "id": "g0T-4rH5qMGR"
      },
      "execution_count": 470,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>\n",
        "\n"
      ],
      "metadata": {
        "id": "515FJX05d4V-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The 'hyperlinks' function removes hyperlinks and various HTML tags from a string.\n",
        "\n",
        "def hyperlinks(text):\n",
        "    temp = re.sub(\"<[a][^>]*>(.+?)</[a]>\", 'Link.',text)\n",
        "    temp = re.sub(r'http\\S+', '', temp)\n",
        "    temp = re.sub('&gt;', \"\", temp) \n",
        "    temp = re.sub('&#x27;', \"'\", temp) \n",
        "    temp = re.sub('&#x2F;', ' ', temp)\n",
        "    temp = re.sub('<p>', ' ', temp) \n",
        "    temp = re.sub('<i>', ' ', temp)\n",
        "    temp = re.sub('</i>', '', temp) \n",
        "    temp = re.sub('&#62;', '', temp)\n",
        "    temp = re.sub(\"\\n\", '', temp)\n",
        "    return temp"
      ],
      "metadata": {
        "id": "jZ7-sZ9kqSPB"
      },
      "execution_count": 471,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>\n",
        "\n"
      ],
      "metadata": {
        "id": "6GaLuKXqd5gf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This 'clean_tweet' function takes a tweet text as input and performs several cleaning tasks to preprocess the text.\n",
        "\n",
        "def clean_tweet(tweet):\n",
        "    temp=tweet.lower() # Converts the tweet text to lowercase.\n",
        "    temp = re.sub(\"'\", \"\", temp) # Avoids removing contractions in English.\n",
        "    temp = re.sub(\"@[A-Za-z0-9_]+\",\"\", temp) # Removes apostrophes and mentions (e.g., \"@username\").\n",
        "    temp = re.sub(\"chatgpt\",\"\",temp) # Removes the word \"chatgpt\".\n",
        "    temp = re.sub(r'http\\S+', '', temp) # Removes hyperlinks.\n",
        "    temp = re.sub('[()!?]', ' ', temp) # Replaces all parentheses, exclamation marks, and question marks with a space.\n",
        "    temp = re.sub('\\[.*?\\]',' ', temp) # Removes square brackets (i.e., removes text that is inside square brackets).\n",
        "    punc=string.punctuation # Removes punctuation marks. \n",
        "    temp=temp.translate(str.maketrans('','',punc)) #Removes all the punctuation marks from the given string 'temp'.\n",
        "    \n",
        "    #Removing stopwords.\n",
        "    new_list=[]\n",
        "    words=word_tokenize(temp)\n",
        "    sws=stopwords.words('english')\n",
        "    for word in words:\n",
        "        if word not in sws:\n",
        "            new_list.append(word)\n",
        "    \n",
        "    temp=' '.join(new_list)\n",
        "    return temp"
      ],
      "metadata": {
        "id": "c6K9Ze14qVxq"
      },
      "execution_count": 472,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>\n",
        "\n"
      ],
      "metadata": {
        "id": "lzQxIV-ad6vj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the TextBlob library to correct any spelling errors in the dataset.\n",
        "\n",
        "def spell_correct(df2):\n",
        "    df2['tweet'].apply(lambda x: str(TextBlob(x).correct()))"
      ],
      "metadata": {
        "id": "SPLVEZs8qamO"
      },
      "execution_count": 473,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "DXRfi-LOqhgG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Lemmatization**"
      ],
      "metadata": {
        "id": "LbFkTRGSqihc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This 'lemmatize' function tokenizes the text and lemmatizes each word using the WordNetLemmatizer from the nltk library, and then joins the resulting list of lemmatized words back into a string.\n",
        "\n",
        "def lemmatize(text):    \n",
        "    new_list=[]\n",
        "    lemma=WordNetLemmatizer()\n",
        "    words=word_tokenize(text)\n",
        "    for word in words:\n",
        "        new_list.append(lemma.lemmatize(word))\n",
        "    \n",
        "    return ' '.join(new_list)"
      ],
      "metadata": {
        "id": "9qnIOWQSqjSc"
      },
      "execution_count": 474,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>"
      ],
      "metadata": {
        "id": "B1-s78luqn-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Applying the previously defined functions to the dataframe to remove hyperlinks, emojis, apostrophes, lemmatize the text and perform additional text cleaning.\n",
        "\n",
        "feat_extract(df_new)\n",
        "\n",
        "df_new['tweet'] = df_new['tweet'].apply(hyperlinks)\n",
        "df_new['tweet'] = df_new['tweet'].apply(remove_emoji)\n",
        "df_new['tweet'] = df_new['tweet'].apply(remove_apostrophe)\n",
        "df_new['tweet'] = df_new['tweet'].apply(clean_tweet)\n",
        "df_new['final_tweet'] = df_new['tweet'].apply(lemmatize)"
      ],
      "metadata": {
        "id": "HUPurKl6qqCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>\n",
        "\n"
      ],
      "metadata": {
        "id": "BKUkx-c_d84r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_new.head()\n"
      ],
      "metadata": {
        "id": "45_Mmed8rN43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "vjzgLRbbry2p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Top 10 most-engaged tweets**"
      ],
      "metadata": {
        "id": "UeeZrUBr6SdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_tweets_df = df_new.sort_values(by='like_count', ascending=False)\n",
        "top_tweets_df.head()"
      ],
      "metadata": {
        "id": "p-mc_c3t3MPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "1x3IIpyw6bzd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Sentiment Analysis**"
      ],
      "metadata": {
        "id": "v4Rvcywfrzgh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialises an instance of the SentimentIntensityAnalyzer class from the NLTK library.\n",
        "\n",
        "sid=SentimentIntensityAnalyzer()"
      ],
      "metadata": {
        "id": "2Og-jj_Or0Ye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>\n",
        "\n"
      ],
      "metadata": {
        "id": "Mr2zHLYyd-uc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Using the SentimentIntensityAnalyzer from the NLTK library to calculate the compound polarity score, neutrality score, negativity score, and positivity score for each tweet in the 'final_tweet' column.\n",
        "\n",
        "df_new['sentiment_compound_polarity']=df_new.final_tweet.apply(lambda x:sid.polarity_scores(x)['compound'])\n",
        "df_new['sentiment_neutral']=df_new.final_tweet.apply(lambda x:sid.polarity_scores(x)['neu'])\n",
        "df_new['sentiment_negative']=df_new.final_tweet.apply(lambda x:sid.polarity_scores(x)['neg'])\n",
        "df_new['sentiment_pos']=df_new.final_tweet.apply(lambda x:sid.polarity_scores(x)['pos'])\n",
        "df_new['sentiment_type']=''\n",
        "\n",
        "df_new.loc[df_new.sentiment_compound_polarity>0,'sentiment_type']='POSITIVE'\n",
        "df_new.loc[df_new.sentiment_compound_polarity==0,'sentiment_type']='NEUTRAL'\n",
        "df_new.loc[df_new.sentiment_compound_polarity<0,'sentiment_type']='NEGATIVE'\n",
        "df_new.head()"
      ],
      "metadata": {
        "id": "XuNOAH66sEWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>\n",
        "\n"
      ],
      "metadata": {
        "id": "elohtGPqeAcE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exporting the output to csv.\n",
        "\n",
        "df_new.to_csv('sentiment.csv', index=False)"
      ],
      "metadata": {
        "id": "cDWgkqGj6UwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "wEp_TZtDsJa7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Sentiment: Bar Chart**\n",
        "\n"
      ],
      "metadata": {
        "id": "TMINOu_UsMPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "colors = [\"#90CECC\", \"#E8D5A1\", \"#E3BAB3\"]\n",
        "\n",
        "sns.barplot(data=df_new,x=df_new['sentiment_type'].value_counts().index,y=df_new['sentiment_type'].value_counts(), palette=colors)\n",
        "plt.title('Sentiment breakdown', fontsize=12)\n"
      ],
      "metadata": {
        "id": "8LTQT2FtsOI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "iWmyD05PsQiC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Sentiment: Pie Chart**"
      ],
      "metadata": {
        "id": "DamQmKsjsR_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "colors = [\"#90CECC\", \"#E8D5A1\", \"#E3BAB3\"]\n",
        "\n",
        "counts = df_new['sentiment_type'].value_counts()\n",
        "fig, ax = plt.subplots()\n",
        "ax.pie(counts.values, labels=counts.index, autopct='%1.1f%%', startangle=90, colors=colors)\n",
        "ax.set_title('Sentiment breakdown')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "m68XKmzpsT2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "xcOaZKGVsUuF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Conversation volume over time**"
      ],
      "metadata": {
        "id": "cccZ9901xctI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting the date to a 'datetime' format\n",
        "df_new['created_at'] = pd.to_datetime(df_new['created_at'])\n",
        "\n",
        "# Grouping the data by day and calculating the count\n",
        "df_daily_count = df_new.groupby(df_new['created_at'].dt.date).size()\n",
        "\n",
        "# Plotting the data on a line chart\n",
        "plt.figure(figsize=(20, 6))\n",
        "plt.plot(df_daily_count.index, df_daily_count.values, color='#E8D5A1')\n",
        "plt.title('Conversation volume over time')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Tweet Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Av3s5OVlxhse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "6Vt3hdPlxiJQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Average sentiment over time**"
      ],
      "metadata": {
        "id": "kG3FWDLrUrxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting the date to a 'datetime' format.\n",
        "df_new['created_at'] = pd.to_datetime(df_new['created_at'])\n",
        "\n",
        "#Grouping the average sentiment data by day. \n",
        "df_sentiment_over_time = df_new.groupby(pd.Grouper(key='created_at', freq='D')).mean(numeric_only=True)\n",
        "\n",
        "#Plotting the data on a line chart. \n",
        "plt.figure(figsize=(20, 6))\n",
        "plt.plot(df_sentiment_over_time.index, df_sentiment_over_time['sentiment_compound_polarity'], color='#E8D5A1')\n",
        "plt.title('Sentiment Over Time')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Sentiment Compound Polarity')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pbG3IeptUuQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ht6shcXkYMsQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Sentiment over time: Daily count per sentiment category**"
      ],
      "metadata": {
        "id": "tt4XbYKXYNkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Group the data by daily time period and sentiment category, and calculating the count\n",
        "df_tweet_count = df_new.groupby([pd.Grouper(key='created_at', freq='D'), 'sentiment_type']).size().unstack()\n",
        "\n",
        "# Plot the count of tweets for each sentiment category over time\n",
        "plt.figure(figsize=(20, 6))\n",
        "plt.plot(df_tweet_count.index, df_tweet_count['POSITIVE'], label='Positive', color='#90CECC')\n",
        "plt.plot(df_tweet_count.index, df_tweet_count['NEGATIVE'], label='Negative', color='#E3BAB3')\n",
        "plt.plot(df_tweet_count.index, df_tweet_count['NEUTRAL'], label='Neutral', color='#E8D5A1')\n",
        "\n",
        "plt.title('Daily Count of Tweets per Sentiment Category')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Tweet Count')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v_hPHJcPp2Iy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "-Dqfpxjqqc4d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Engagement over time**"
      ],
      "metadata": {
        "id": "DYDHx9Usqdny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting the date to a 'datetime' format\n",
        "df_new['created_at'] = pd.to_datetime(df_new['created_at'])\n",
        "\n",
        "# Calculating the total engagement per day.\n",
        "daily_engagement = df_new[['like_count', 'quote_count', 'reply_count', 'retweet_count']].sum(axis=1)\n",
        "\n",
        "# Grouping the data by day\n",
        "df_daily_engagement = df_new.groupby(pd.Grouper(key='created_at', freq='D')).sum(numeric_only=True)\n",
        "\n",
        "# Plotting the data on a line chart\n",
        "plt.figure(figsize=(20, 6))\n",
        "plt.plot(df_daily_engagement.index, df_daily_engagement['like_count'] + df_daily_engagement['quote_count'] + df_daily_engagement['reply_count'] + df_daily_engagement['retweet_count'], color='#E8D5A1')\n",
        "plt.title('Engagement Over Time')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Engagement per Day')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "zsL9G08Kvs9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "hg928eIuqvDc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Word Cloud: Positive Tweets**"
      ],
      "metadata": {
        "id": "scGNXBBOsZ1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a new data frame that shows the 30 most common words in the 'final_tweet' column of 'eda'. \n",
        "\n",
        "eda=df_new.copy()\n",
        "\n",
        "eda['temp_list'] = eda['final_tweet'].apply(lambda x:str(x).split())\n",
        "top = Counter([item for sublist in eda['temp_list'] for item in sublist])\n",
        "temp = pd.DataFrame(top.most_common(30))\n",
        "temp.columns = ['Common_words','count']\n",
        "\n",
        "# Creating the word cloud using text from positive-sentiment tweets.\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "text=' '.join(eda[eda['sentiment_type']=='POSITIVE']['final_tweet'])\n",
        "wordcloud=WordCloud(max_words=100, background_color='white', colormap='Greens').generate(text)\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis('off')\n",
        "plt.title('Wordcloud: Positive Tweets')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1XZyNLodsaeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "6LF4thrasdB1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Word Cloud: Negative Tweets**"
      ],
      "metadata": {
        "id": "00zbKEt-sflI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the word cloud using text from negative-sentiment tweets.\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "text=' '.join(eda[eda['sentiment_type']=='NEGATIVE']['final_tweet'])\n",
        "wordcloud=WordCloud(max_words=100,background_color='white',colormap='Reds').generate(text)\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis('off')\n",
        "plt.title('Wordcloud: Negative Tweets')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "W47f9p2BsgFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "MGSodKYMsn26"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Topic Analysis: Use-cases**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Lxa2Qb4bsolt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining and labelling the keyword groups for analysis. \n",
        "use_cases = {'Programming': ['python', 'programming', 'coding', 'code', 'syntax', 'debug', 'debugging', 'markdown', 'error-check', 'shinyapps', 'react', 'ruby on rails'],\n",
        "                  'Writing': ['writing', 'essay', 'assignment', 'write', 'stories', 'story', 'post', 'blog', 'article'],\n",
        "                  'Communication': ['text', 'message', 'email', 'letter', 'memo', 'meeting'],\n",
        "                  'Research': ['research', 'search', 'wiki', 'wikipedia', 'paper', 'dissertation', 'thesis'],\n",
        "                  'Creativity': ['idea', 'ideas', 'poem', 'haiku', 'song', 'episode', 'rhyme', 'lyrics', 'art', 'portrait', 'rap'],\n",
        "                  'Education': ['exam', 'assignment', 'essay', 'tutor', 'homework', 'undergraduate', 'student', 'teacher', 'quiz', 'papers']}\n",
        "\n",
        "# Creating a dictionary to store the count of tweets for each group.\n",
        "use_cases_counts = {}\n",
        "\n",
        "# Looping over the keyword groups and count the number of tweets that contain any keyword in the group.\n",
        "for group_label, group_keywords in use_cases.items():\n",
        "    mask = df['tweet'].str.contains('|'.join(group_keywords), case=False)\n",
        "    use_cases_counts[group_label] = mask.sum()\n",
        "\n",
        "# Calculating the total number of tweets in the dataset.\n",
        "total_tweets = len(df)\n",
        "\n",
        "# Looping over the keyword groups and calculate the percentage of tweets that contain any keyword in the group.\n",
        "for group_label, group_count in use_cases_counts.items():\n",
        "    group_percentage = group_count / total_tweets * 100\n",
        "    print(f'The \"{group_label}\" group appears in {group_percentage:.2f}% of the tweets.')"
      ],
      "metadata": {
        "id": "spTe9xr8sp2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>\n",
        "\n"
      ],
      "metadata": {
        "id": "vljBZcDjeEI6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "A7VVKuRPst5A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Topic Analysis: Use-cases > Bar chart**"
      ],
      "metadata": {
        "id": "6OQ2M4Mbsuo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a list of the percentage of tweets that contain each keyword group.\n",
        "use_cases_percentages = [(group_label, group_count / total_tweets * 100) for group_label, group_count in use_cases_counts.items()]\n",
        "\n",
        "# Sorting the list by percentage in descending order.\n",
        "use_cases_percentages.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Extracting the group labels and percentages into separate lists.\n",
        "group_labels = [x[0] for x in use_cases_percentages]\n",
        "use_cases_percentages = [x[1] for x in use_cases_percentages]\n",
        "\n",
        "# Creating a bar chart of the group percentages.\n",
        "sns.barplot(x=group_labels, y=use_cases_percentages, palette='Set2')\n",
        "plt.title('Percentage of Tweets by Keyword Group', fontsize=12)\n",
        "plt.xlabel('Keyword Group', fontsize=10)\n",
        "plt.ylabel('Percentage of Tweets', fontsize=10)\n",
        "plt.xticks(fontsize=8) #change x-axis tick label size\n",
        "plt.yticks(fontsize=8) #change y-axis tick label size\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lLo_mg_ksx95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Exporting the output for visualisation.\n",
        "\n",
        "# Define the file name for the CSV output\n",
        "filename = \"use_cases_group_counts.csv\"\n",
        "\n",
        "# Open the CSV file and write the header row\n",
        "with open(filename, \"w\", newline=\"\") as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow([\"Keyword Group\", \"Tweet Count\"])\n",
        "\n",
        "    # Loop through each group and write the label and count to the CSV\n",
        "    for group, count in use_cases_counts.items():\n",
        "        writer.writerow([group, count])"
      ],
      "metadata": {
        "id": "JddcQhhx82Lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "h3JV1jJNsyo7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Topic Sentiment Analysis: Programming**"
      ],
      "metadata": {
        "id": "pJSxVE81HLS3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the list of keywords for the 'Programming' category. \n",
        "programming_keywords = ['python', 'programming', 'coding', 'code', 'syntax', 'debug', 'debugging', 'markdown', 'error-check', 'shinyapps', 'react', 'ruby on rails']\n",
        "\n",
        "# Creating a new dataframe with tweets containing the keywords. \n",
        "programming = df_new[df_new['final_tweet'].str.contains('|'.join(programming_keywords))]\n",
        "\n",
        "# Initializing the SentimentIntensityAnalyzer from NLTK.\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Applying a sentiment classification to each of the keywords in the group.  \n",
        "programming.loc[programming.sentiment_compound_polarity>0,'sentiment_type']='POSITIVE'\n",
        "programming.loc[programming.sentiment_compound_polarity==0,'sentiment_type']='NEUTRAL'\n",
        "programming.loc[programming.sentiment_compound_polarity<0,'sentiment_type']='NEGATIVE'\n",
        "\n",
        "programming.head()"
      ],
      "metadata": {
        "id": "fOxricYyUhvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>\n",
        "\n"
      ],
      "metadata": {
        "id": "7iA9kO1aeHHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating the mean sentiment for the 'Programming' keyword group.\n",
        "\n",
        "# group the rows by sentiment type and calculate the mean sentiment score for each group\n",
        "mean_sentiment = programming.groupby('sentiment_type')['sentiment_compound_polarity'].mean()\n",
        "\n",
        "print(mean_sentiment)"
      ],
      "metadata": {
        "id": "10teNUyiU1TT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>\n",
        "\n"
      ],
      "metadata": {
        "id": "A5BiHhoueIVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exporting the output to for data visualisation.\n",
        "\n",
        "programming.to_csv('programming.csv', index=False)"
      ],
      "metadata": {
        "id": "FqjgRvWAU7ju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Qkc5emn2H54C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Sentiment bar chart: Programming**"
      ],
      "metadata": {
        "id": "jNrBFCQ1bDpT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "colors = [\"#90CECC\", \"#E8D5A1\", \"#E3BAB3\"]\n",
        "\n",
        "sns.barplot(data=programming,x=programming['sentiment_type'].value_counts().index,y=programming['sentiment_type'].value_counts(), palette=colors)\n",
        "\n",
        "plt.title('Use-case: Progamming', fontsize=12)"
      ],
      "metadata": {
        "id": "5NSKePUmb4oE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "vnavq3NubEUK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Topic Sentiment Analysis: Writing**"
      ],
      "metadata": {
        "id": "8PHVcglgJyvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the list of keywords for the 'Writing' category. \n",
        "writing_keywords = ['writing', 'essay', 'assignment', 'write', 'stories', 'story', 'post', 'blog', 'article']\n",
        "\n",
        "# Creating a new dataframe with tweets containing the keywords. \n",
        "writing = df_new[df_new['final_tweet'].str.contains('|'.join(writing_keywords))]\n",
        "\n",
        "# Initializing the SentimentIntensityAnalyzer from NLTK.\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Applying a sentiment classification to each of the keywords in the group.  \n",
        "writing.loc[writing.sentiment_compound_polarity>0,'sentiment_type']='POSITIVE'\n",
        "writing.loc[writing.sentiment_compound_polarity==0,'sentiment_type']='NEUTRAL'\n",
        "writing.loc[writing.sentiment_compound_polarity<0,'sentiment_type']='NEGATIVE'\n",
        "\n",
        "writing.head()"
      ],
      "metadata": {
        "id": "j_83baJ6VAOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>\n",
        "\n"
      ],
      "metadata": {
        "id": "ia2u0PbpeKt2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating the mean sentiment for the 'Writing' keyword group.\n",
        "\n",
        "# group the rows by sentiment type and calculate the mean sentiment score for each group\n",
        "mean_sentiment = writing.groupby('sentiment_type')['sentiment_compound_polarity'].mean()\n",
        "\n",
        "print(mean_sentiment)"
      ],
      "metadata": {
        "id": "askf9OFvVEgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>\n",
        "\n"
      ],
      "metadata": {
        "id": "o6NlkINHeMEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exporting the output to for data visualisation.\n",
        "\n",
        "writing.to_csv('writing.csv', index=False)"
      ],
      "metadata": {
        "id": "dzkccshEVJ6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "6vKJ-T5aKHI5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Sentiment bar chart: Writing**"
      ],
      "metadata": {
        "id": "bldt-nGcbIqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "colors = [\"#90CECC\", \"#E8D5A1\", \"#E3BAB3\"]\n",
        "\n",
        "sns.barplot(data=writing,x=writing['sentiment_type'].value_counts().index,y=writing['sentiment_type'].value_counts(), palette=colors)\n",
        "\n",
        "plt.title('Use-case: Writing', fontsize=12)"
      ],
      "metadata": {
        "id": "wIB9B5S5cCai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Ph42NAiZbK3g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Topic Sentiment Analysis: Communication**"
      ],
      "metadata": {
        "id": "W8QDE9enKOSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the list of keywords for the 'Communication' category. \n",
        "communication_keywords = ['text', 'message', 'email', 'letter', 'memo', 'meeting']\n",
        "\n",
        "# Creating a new dataframe with tweets containing the keywords. \n",
        "communication = df_new[df_new['final_tweet'].str.contains('|'.join(communication_keywords))]\n",
        "\n",
        "# Initializing the SentimentIntensityAnalyzer from NLTK.\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Applying a sentiment classification to each of the keywords in the group.  \n",
        "communication.loc[communication.sentiment_compound_polarity>0,'sentiment_type']='POSITIVE'\n",
        "communication.loc[communication.sentiment_compound_polarity==0,'sentiment_type']='NEUTRAL'\n",
        "communication.loc[communication.sentiment_compound_polarity<0,'sentiment_type']='NEGATIVE'\n",
        "\n",
        "communication.head()"
      ],
      "metadata": {
        "id": "ETVM2j2XVPCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>\n",
        "\n"
      ],
      "metadata": {
        "id": "5vj3QhYQeNvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating the mean sentiment for the 'Communication' keyword group.\n",
        "\n",
        "# group the rows by sentiment type and calculate the mean sentiment score for each group\n",
        "mean_sentiment = communication.groupby('sentiment_type')['sentiment_compound_polarity'].mean()\n",
        "\n",
        "print(mean_sentiment)"
      ],
      "metadata": {
        "id": "5aaJI70sVp1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>\n",
        "\n"
      ],
      "metadata": {
        "id": "8m-6FexKePAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exporting the output to for data visualisation.\n",
        "\n",
        "communication.to_csv('communication.csv', index=False)"
      ],
      "metadata": {
        "id": "WhwckzVXVzn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "zRX-i3fHKmYc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Sentiment bar chart: Communication**"
      ],
      "metadata": {
        "id": "kfvz_DilbMqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "colors = [\"#90CECC\", \"#E8D5A1\", \"#E3BAB3\"]\n",
        "\n",
        "sns.barplot(data=communication,x=communication['sentiment_type'].value_counts().index,y=communication['sentiment_type'].value_counts(), palette=colors)\n",
        "\n",
        "plt.title('Use-case: Communication', fontsize=12)"
      ],
      "metadata": {
        "id": "czcVWP_McNpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "KseNKoy9bObx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Topic Sentiment Analysis: Research**"
      ],
      "metadata": {
        "id": "hSytz5jRTSka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the list of keywords for the 'Research' category. \n",
        "research_keywords = ['research', 'search', 'wiki', 'wikipedia', 'paper', 'dissertation', 'thesis']\n",
        "\n",
        "# Creating a new dataframe with tweets containing the keywords. \n",
        "research = df_new[df_new['final_tweet'].str.contains('|'.join(research_keywords))]\n",
        "\n",
        "# Initializing the SentimentIntensityAnalyzer from NLTK.\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Applying a sentiment classification to each of the keywords in the group.  \n",
        "research.loc[research.sentiment_compound_polarity>0,'sentiment_type']='POSITIVE'\n",
        "research.loc[research.sentiment_compound_polarity==0,'sentiment_type']='NEUTRAL'\n",
        "research.loc[research.sentiment_compound_polarity<0,'sentiment_type']='NEGATIVE'\n",
        "\n",
        "research.head()"
      ],
      "metadata": {
        "id": "wvr4tP0rV58y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>\n",
        "\n"
      ],
      "metadata": {
        "id": "MWTXCO9veQlb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating the mean sentiment for the 'Research' keyword group.\n",
        "\n",
        "# group the rows by sentiment type and calculate the mean sentiment score for each group\n",
        "mean_sentiment = research.groupby('sentiment_type')['sentiment_compound_polarity'].mean()\n",
        "\n",
        "print(mean_sentiment)"
      ],
      "metadata": {
        "id": "-8qH5ajwWM-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>\n",
        "\n"
      ],
      "metadata": {
        "id": "Wy8BznQ3eSHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exporting the output to for data visualisation.\n",
        "\n",
        "research.to_csv('research.csv', index=False)"
      ],
      "metadata": {
        "id": "HWR5fjMWWXa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "pUbCuS5lTZ62"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Sentiment bar chart: Research**"
      ],
      "metadata": {
        "id": "-LkQCZ4XbQBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "colors = [\"#90CECC\", \"#E8D5A1\", \"#E3BAB3\"]\n",
        "\n",
        "sns.barplot(data=research,x=research['sentiment_type'].value_counts().index,y=research['sentiment_type'].value_counts(), palette=colors)\n",
        "\n",
        "plt.title('Use-case: Research', fontsize=12)"
      ],
      "metadata": {
        "id": "1JMQJfvLcU4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "6vS5m8MebR65"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Topic Sentiment Analysis: Creativity**\n",
        "\n"
      ],
      "metadata": {
        "id": "WZUvlGhDTaiw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the list of keywords for the 'Creativity' category. \n",
        "creativity_keywords = ['idea', 'ideas', 'poem', 'haiku', 'song', 'episode', 'rhyme', 'lyrics', 'art', 'portrait', 'rap']\n",
        "\n",
        "# Creating a new dataframe with tweets containing the keywords. \n",
        "creativity = df_new[df_new['final_tweet'].str.contains('|'.join(creativity_keywords))]\n",
        "\n",
        "# Initializing the SentimentIntensityAnalyzer from NLTK.\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Applying a sentiment classification to each of the keywords in the group.  \n",
        "creativity.loc[creativity.sentiment_compound_polarity>0,'sentiment_type']='POSITIVE'\n",
        "creativity.loc[creativity.sentiment_compound_polarity==0,'sentiment_type']='NEUTRAL'\n",
        "creativity.loc[creativity.sentiment_compound_polarity<0,'sentiment_type']='NEGATIVE'\n",
        "\n",
        "creativity.head()"
      ],
      "metadata": {
        "id": "aMDEbRoJWbyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>\n",
        "\n"
      ],
      "metadata": {
        "id": "exUNsUIbeT6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating the mean sentiment for the 'Creativity' keyword group.\n",
        "\n",
        "# group the rows by sentiment type and calculate the mean sentiment score for each group\n",
        "mean_sentiment = creativity.groupby('sentiment_type')['sentiment_compound_polarity'].mean()\n",
        "\n",
        "print(mean_sentiment)"
      ],
      "metadata": {
        "id": "Hcj7IrocWvqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>\n",
        "\n"
      ],
      "metadata": {
        "id": "FViGRK0veVUM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exporting the output to for data visualisation.\n",
        "\n",
        "creativity.to_csv('creativity.csv', index=False)"
      ],
      "metadata": {
        "id": "r9XryNLOW6hW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "YZBCrT6ETiWz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Sentiment bar chart: Creativity**"
      ],
      "metadata": {
        "id": "8OIA6UMJbT-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "colors = [\"#90CECC\", \"#E8D5A1\", \"#E3BAB3\"]\n",
        "\n",
        "sns.barplot(data=creativity,x=creativity['sentiment_type'].value_counts().index,y=creativity['sentiment_type'].value_counts(),palette=colors)\n",
        "\n",
        "plt.title('Use-case: Creativity', fontsize=12)"
      ],
      "metadata": {
        "id": "eGPPm_Wicdhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "30V0HrX-bW0O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Topic Sentiment Analysis: Education**"
      ],
      "metadata": {
        "id": "caFCOzVtTjaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the list of keywords for the 'Education' category. \n",
        "education_keywords = ['exam', 'assignment', 'essay', 'tutor', 'homework', 'undergraduate', 'student', 'teacher', 'quiz', 'papers']\n",
        "\n",
        "# Creating a new dataframe with tweets containing the keywords. \n",
        "education = df_new[df_new['final_tweet'].str.contains('|'.join(education_keywords))]\n",
        "\n",
        "# Initializing the SentimentIntensityAnalyzer from NLTK.\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Applying a sentiment classification to each of the keywords in the group.  \n",
        "education.loc[education.sentiment_compound_polarity>0,'sentiment_type']='POSITIVE'\n",
        "education.loc[education.sentiment_compound_polarity==0,'sentiment_type']='NEUTRAL'\n",
        "education.loc[education.sentiment_compound_polarity<0,'sentiment_type']='NEGATIVE'\n",
        "\n",
        "education.head()\n"
      ],
      "metadata": {
        "id": "0d_76KPAXBc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>\n",
        "\n"
      ],
      "metadata": {
        "id": "uW-b3fpleW5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating the mean sentiment for the 'Education' keyword group.\n",
        "\n",
        "# group the rows by sentiment type and calculate the mean sentiment score for each group\n",
        "mean_sentiment = education.groupby('sentiment_type')['sentiment_compound_polarity'].mean()\n",
        "\n",
        "print(mean_sentiment)"
      ],
      "metadata": {
        "id": "ard51y6DXWW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>\n",
        "\n"
      ],
      "metadata": {
        "id": "R1_0pZVmeYee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exporting the output to for data visualisation.\n",
        "\n",
        "education.to_csv('education.csv', index=False)"
      ],
      "metadata": {
        "id": "Sy_aLiNgXcO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "wfauhNMgeZyK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Sentiment bar chart: Education**"
      ],
      "metadata": {
        "id": "5ZHVGReXbYR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "colors = [\"#90CECC\", \"#E3BAB3\", \"#E8D5A1\"]\n",
        "\n",
        "sns.barplot(data=education,x=education['sentiment_type'].value_counts().index,y=education['sentiment_type'].value_counts(),palette=colors)\n",
        "\n",
        "plt.title('Use-case: Education', fontsize=12)"
      ],
      "metadata": {
        "id": "obXOjQmuc7c2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "JfMrbHH1baB5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Topic Analysis: Common issues**"
      ],
      "metadata": {
        "id": "TLW9b_JPs1gS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining and labelling the keyword groups for analysis. \n",
        "common_issues = {'Hallucinations': ['hallucination', 'hallucinate', 'unfactual', 'incorrect', 'inaccurate', 'unverified'],\n",
        "                  'Ethical implications': ['ethics', 'bias', 'ethical', 'plagiarism', 'copyright'],\n",
        "                  'Disinformation': ['disinformation', 'misinformation', 'libel', 'slander', 'propaganda'],\n",
        "                  'Abusive Language': ['racism', 'racist', 'misogyny', 'sexism', 'sexist', 'hate speech', 'abusive language', 'anti-semitism']}\n",
        "\n",
        "# Creating a dictionary to store the count of tweets for each group.\n",
        "common_issues_counts = {}\n",
        "\n",
        "# Looping over the keyword groups and counting the number of tweets that contain any keyword in the group.\n",
        "for group_label, group_keywords in common_issues.items():\n",
        "    mask = df['tweet'].str.contains('|'.join(group_keywords), case=False)\n",
        "    common_issues_counts[group_label] = mask.sum()\n",
        "\n",
        "# Calculating the total number of tweets in the dataset.\n",
        "total_tweets = len(df)\n",
        "\n",
        "# Looping over the keyword groups and calculate the percentage of tweets that contain any keyword in the group.\n",
        "for group_label, group_count in common_issues_counts.items():\n",
        "    group_percentage = group_count / total_tweets * 100\n",
        "    print(f'The \"{group_label}\" group appears in {group_percentage:.2f}% of the tweets.')"
      ],
      "metadata": {
        "id": "A39ipL4ys3Nx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>\n",
        "\n"
      ],
      "metadata": {
        "id": "lODmoU97eevW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "n8822rDEs48b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Topic Analysis: Common issues > Bar chart**"
      ],
      "metadata": {
        "id": "ZhY4jWzRs8Gg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a list of the percentage of tweets that contain each keyword group.\n",
        "common_issues_percentages = [(group_label, group_count / total_tweets * 100) for group_label, group_count in group_counts.items()]\n",
        "\n",
        "# Sorting the list by percentage in descending order.\n",
        "common_issues_percentages.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Extracting the group labels and percentages into separate lists.\n",
        "group_labels = [x[0] for x in common_issues_percentages]\n",
        "common_issues_percentages = [x[1] for x in common_issues_percentages]\n",
        "\n",
        "# Creating a bar chart of the group percentages.\n",
        "sns.barplot(x=group_labels, y=common_issues_percentages, palette='Set2')\n",
        "plt.title('Percentage of Tweets by Keyword Group', fontsize=12)\n",
        "plt.xlabel('Keyword Group', fontsize=10)\n",
        "plt.ylabel('Percentage of Tweets', fontsize=10)\n",
        "plt.xticks(fontsize=8) #change x-axis tick label size\n",
        "plt.yticks(fontsize=8) #change y-axis tick label size\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xqOEge8es-0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "_qVt38YLs_kK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Topic Sentiment Analysis: Hallucinations**\n",
        "\n"
      ],
      "metadata": {
        "id": "6ulcx0ieTsxT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the list of keywords for the 'Hallucinations' category. \n",
        "hallucination_keywords = ['hallucination', 'hallucinate', 'unfactual', 'incorrect', 'inaccurate', 'unverified']\n",
        "\n",
        "# Creating a new dataframe with tweets containing the keywords. \n",
        "hallucinations = df_new[df_new['final_tweet'].str.contains('|'.join(hallucination_keywords))]\n",
        "\n",
        "# Initializing the SentimentIntensityAnalyzer from NLTK.\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Applying a sentiment classification to each of the keywords in the group.  \n",
        "hallucinations.loc[hallucinations.sentiment_compound_polarity>0,'sentiment_type']='POSITIVE'\n",
        "hallucinations.loc[hallucinations.sentiment_compound_polarity==0,'sentiment_type']='NEUTRAL'\n",
        "hallucinations.loc[hallucinations.sentiment_compound_polarity<0,'sentiment_type']='NEGATIVE'\n",
        "\n",
        "hallucinations.head()"
      ],
      "metadata": {
        "id": "TLxp5dGOX6FP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>\n",
        "\n"
      ],
      "metadata": {
        "id": "nVnhOXNoehNL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating the mean sentiment for the 'Hallucinations' keyword group.\n",
        "\n",
        "# group the rows by sentiment type and calculate the mean sentiment score for each group\n",
        "mean_sentiment = hallucinations.groupby('sentiment_type')['sentiment_compound_polarity'].mean()\n",
        "\n",
        "print(mean_sentiment)"
      ],
      "metadata": {
        "id": "QUgreRAGX9Wb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>\n",
        "\n"
      ],
      "metadata": {
        "id": "eDkLNK-reif-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exporting the output to for data visualisation.\n",
        "\n",
        "hallucinations.to_csv('hallucinations.csv', index=False)"
      ],
      "metadata": {
        "id": "Xn7f0MmAX-3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "dKYqMB1YUHQy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Sentiment bar chart: Hallucinations**"
      ],
      "metadata": {
        "id": "xsNh6FvJbbai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "colors = [\"#90CECC\", \"#E3BAB3\", \"#E8D5A1\"]\n",
        "\n",
        "sns.barplot(data=hallucinations,x=hallucinations['sentiment_type'].value_counts().index,y=hallucinations['sentiment_type'].value_counts(),palette=colors)\n",
        "\n",
        "plt.title('Common issues: Hallucinations', fontsize=12)"
      ],
      "metadata": {
        "id": "DiYtHlgTdD-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "HZwaB32_bpZl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Topic Sentiment Analysis: Ethical concerns**\n",
        "\n"
      ],
      "metadata": {
        "id": "2eCQBEj9Twab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the list of keywords for the 'Ethical concerns' category. \n",
        "ethics_keywords = ['ethics', 'bias', 'ethical', 'plagiarism', 'copyright']\n",
        "\n",
        "# Creating a new dataframe with tweets containing the keywords. \n",
        "ethics = df_new[df_new['final_tweet'].str.contains('|'.join(ethics_keywords))]\n",
        "\n",
        "# Initializing the SentimentIntensityAnalyzer from NLTK.\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Applying a sentiment classification to each of the keywords in the group.  \n",
        "ethics.loc[ethics.sentiment_compound_polarity>0,'sentiment_type']='POSITIVE'\n",
        "ethics.loc[ethics.sentiment_compound_polarity==0,'sentiment_type']='NEUTRAL'\n",
        "ethics.loc[ethics.sentiment_compound_polarity<0,'sentiment_type']='NEGATIVE'\n",
        "\n",
        "ethics.head()"
      ],
      "metadata": {
        "id": "QXMzVh36YA0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>\n",
        "\n"
      ],
      "metadata": {
        "id": "_3dMJG_-ekHY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating the mean sentiment for the 'Ethical concerns' keyword group.\n",
        "\n",
        "# group the rows by sentiment type and calculate the mean sentiment score for each group\n",
        "mean_sentiment = ethics.groupby('sentiment_type')['sentiment_compound_polarity'].mean()\n",
        "\n",
        "print(mean_sentiment)"
      ],
      "metadata": {
        "id": "TL1_Z9HvYCSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>\n",
        "\n"
      ],
      "metadata": {
        "id": "SI3CqXNgelV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exporting the output to for data visualisation.\n",
        "\n",
        "ethics.to_csv('ethics.csv', index=False)\n"
      ],
      "metadata": {
        "id": "3i3rgeEBYJhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "wgUVpNplUIM2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Sentiment bar chart: Ethical concerns**"
      ],
      "metadata": {
        "id": "1IFXZXTCbrPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "colors = [\"#90CECC\", \"#E3BAB3\", \"#E8D5A1\"]\n",
        "\n",
        "sns.barplot(data=ethics,x=ethics['sentiment_type'].value_counts().index,y=ethics['sentiment_type'].value_counts(),palette=colors)\n",
        "\n",
        "plt.title('Common issues: Ethical concerns', fontsize=12)"
      ],
      "metadata": {
        "id": "Tzk4OnD3dKXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "IS-A5rL_bt0M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Topic Sentiment Analysis: Disinformation**\n",
        "\n"
      ],
      "metadata": {
        "id": "IY9vCpDZTx4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the list of keywords for the 'Disinformation' category. \n",
        "disinformation_keywords = ['disinformation', 'misinformation', 'libel', 'slander', 'propaganda']\n",
        "\n",
        "# Creating a new dataframe with tweets containing the keywords. \n",
        "disinformation = df_new[df_new['final_tweet'].str.contains('|'.join(disinformation_keywords))]\n",
        "\n",
        "# Initializing the SentimentIntensityAnalyzer from NLTK.\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Applying a sentiment classification to each of the keywords in the group.  \n",
        "disinformation.loc[disinformation.sentiment_compound_polarity>0,'sentiment_type']='POSITIVE'\n",
        "disinformation.loc[disinformation.sentiment_compound_polarity==0,'sentiment_type']='NEUTRAL'\n",
        "disinformation.loc[disinformation.sentiment_compound_polarity<0,'sentiment_type']='NEGATIVE'\n",
        "\n",
        "disinformation.head()"
      ],
      "metadata": {
        "id": "qUmcKrEDYDy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>\n",
        "\n"
      ],
      "metadata": {
        "id": "Rz5Cfp_Ien9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating the mean sentiment for the 'Disinformation' keyword group.\n",
        "\n",
        "# group the rows by sentiment type and calculate the mean sentiment score for each group\n",
        "mean_sentiment = disinformation.groupby('sentiment_type')['sentiment_compound_polarity'].mean()\n",
        "\n",
        "print(mean_sentiment)"
      ],
      "metadata": {
        "id": "UTTBNrFBYGPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>\n",
        "\n"
      ],
      "metadata": {
        "id": "1zlF5js7eqGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exporting the output to for data visualisation.\n",
        "\n",
        "disinformation.to_csv('disinformation.csv', index=False)\n"
      ],
      "metadata": {
        "id": "TV_VhF5iYKSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ur7NclKzUQAt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Sentiment bar chart: Disinformation**"
      ],
      "metadata": {
        "id": "d_z7VZcwbvVD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "colors = [\"#E3BAB3\", \"#90CECC\", \"#E8D5A1\"]\n",
        "\n",
        "sns.barplot(data=disinformation,x=disinformation['sentiment_type'].value_counts().index,y=disinformation['sentiment_type'].value_counts(),palette=colors)\n",
        "\n",
        "plt.title('Common issues: Disinformation', fontsize=12)"
      ],
      "metadata": {
        "id": "k2Mkm-NfdSJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "5MEI-IUzbx5N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Topic Sentiment Analysis: Abusive Language**"
      ],
      "metadata": {
        "id": "C8R6U0CITyMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the list of keywords for the 'Abusive Language' category. \n",
        "language_keywords = ['racism', 'racist', 'misogyny', 'sexism', 'sexist', 'hate speech', 'abusive language', 'anti-semitism']\n",
        "\n",
        "# Creating a new dataframe with tweets containing the keywords. \n",
        "abusivelang = df_new[df_new['final_tweet'].str.contains('|'.join(language_keywords))]\n",
        "\n",
        "# Initializing the SentimentIntensityAnalyzer from NLTK.\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Applying a sentiment classification to each of the keywords in the group.  \n",
        "abusivelang.loc[abusivelang.sentiment_compound_polarity>0,'sentiment_type']='POSITIVE'\n",
        "abusivelang.loc[abusivelang.sentiment_compound_polarity==0,'sentiment_type']='NEUTRAL'\n",
        "abusivelang.loc[abusivelang.sentiment_compound_polarity<0,'sentiment_type']='NEGATIVE'\n",
        "\n",
        "abusivelang.head()"
      ],
      "metadata": {
        "id": "FXYt4LdJYEal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>\n",
        "\n"
      ],
      "metadata": {
        "id": "ViQJKT8verla"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating the mean sentiment for the 'Abusive Language' keyword group.\n",
        "\n",
        "# group the rows by sentiment type and calculate the mean sentiment score for each group\n",
        "mean_sentiment = abusivelang.groupby('sentiment_type')['sentiment_compound_polarity'].mean()\n",
        "\n",
        "print(mean_sentiment)"
      ],
      "metadata": {
        "id": "o16JJJMYYG0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>\n",
        "\n"
      ],
      "metadata": {
        "id": "yKBytIPbes1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exporting the output to for data visualisation.\n",
        "\n",
        "abusivelang.to_csv('abusivelang.csv', index=False)\n"
      ],
      "metadata": {
        "id": "JY-Tdg59YLEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "AQL_v0JpTu2g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Sentiment bar chart: Abusive Language**"
      ],
      "metadata": {
        "id": "j-baNDoya3Xt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "colors = [\"#E3BAB3\", \"#90CECC\", \"#E8D5A1\"]\n",
        "\n",
        "sns.barplot(data=abusivelang,x=abusivelang['sentiment_type'].value_counts().index,y=abusivelang['sentiment_type'].value_counts(),palette=colors)\n",
        "\n",
        "plt.title('Common issues: Abusive Language', fontsize=12)"
      ],
      "metadata": {
        "id": "E0m1ZiL0ai8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ozpkC4QBaxyt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Topline Engagement Metrics: Calculations for visualisation**"
      ],
      "metadata": {
        "id": "TQ3v_19mDm1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating the total like count\n",
        "df_new.like_count.sum()"
      ],
      "metadata": {
        "id": "ndXWJUphGOyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating the total quote count\n",
        "df_new.quote_count.sum()"
      ],
      "metadata": {
        "id": "q2GvKqdEG0G7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating the total reply count\n",
        "df_new.reply_count.sum()"
      ],
      "metadata": {
        "id": "EoQIR5KDG6ka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating the total retweet count\n",
        "df_new.retweet_count.sum()"
      ],
      "metadata": {
        "id": "YaDIv2S1G-em"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "C4OCJwYjxS9a"
      }
    }
  ]
}
